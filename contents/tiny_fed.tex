\chapter{TinyFed方法}

根据上一章所介绍并初步验证的低秩轨迹假设\ref{hyp:low_dimensional}，我们给出在联邦学习场景下基于模型训练轨迹进行低秩降维压缩方法，简称为TinyFed方法（后文均简称为TinyFed）。在本章中，我们将介绍低秩轨迹假设在联邦学习框架应用的主要意义和难点，而后将给出TinyFed方法的具体算法思路及实现，并以具体数据集中的实验设计对该算法的性能进行评估，最后给出一系列消融性实验作为补充。

\section{TinyFed方法背景}

本小节中我们将结合降维压缩的相关工作给出低秩轨迹假设以及动态线性降维方法在联邦学习中应用的意义和难点。

\subsection{低秩轨迹假设在联邦学习中应用的意义}

由绪论和相关工作中的一些介绍我们知道，通信效率问题是制约联邦学习发展的一大瓶颈，在当客户端数量成百上千时，每一轮迭代中系统内所有客户端上传模型更新与下载全局模型所需的时间便愈发庞大。因此若能在低秩轨迹假设的基础上，令每一轮迭代过程中，客户端仅需上传降维压缩后的模型更新信息（相对于原本整个模型参数只需几千乃至几十的浮点数），能够极大提升联邦学习中通信效率。

在现有的降维压缩方法研究中，通常采取将神经网络模型分不同的结构进行降维，如单独对多层感知机（multi-layer perceptron）的参数矩阵进行降维或对卷积神经网络（convolutional neural network）结构进行降维。这样的策略确实能够根据网络结构特点应用常规低秩分解（如主成分分析）方法，然而也存在局限：将神经网络各个组成部分分开单独降维，忽视了各个组成部分的参数间亦存在一定的相关性，会导致降维压缩的结果仍存在一定冗余。这也是现有方法中降维目标子空间维度仍数以千计的原因（如\parencite{li2018measuring}将LENET结构降维压缩至$2900$维）。而基于轨迹的低秩降维方法，能够将模型的所有参数作为压缩的对象，在上一章的实验中能够达到在降维到$20$个独立变量的情况下进行训练，且性能接近甚至优于常规随机梯度下降方法。因此，低秩轨迹假设

\subsection{低秩轨迹假设在联邦学习中应用的难点}

\section{TinyFed方法思路及算法}

\subsection{轨迹采样阶段}

\subsection{低秩降维及降维矩阵分发阶段}

\subsection{TinyFed训练阶段}


\section{联邦学习场景下实验部分}

\subsection{数据集及划分}

\subsection{模型结构}

\subsection{实验设计}

\subsection{实验结果}


1. 利用模型训练轨迹进行模型降维压缩
在前期对比各类模型压缩方法后，本课题选择采用PCA降维的方法来降低模型通信开销。采用降维方法后的联邦学习一轮训练过程为：
1. 本地训练：所有客户端根据自身存储的数据计算梯度或参数，并根据特定的降维PCA（主成分）矩阵压缩本地模型，将压缩后的模型上传至服务端。
2. 模型聚合：服务端聚合各个客户端上传的压缩后模型，并根据特定的降维PCA矩阵的逆矩阵重建压缩后的模型。
3. 参数广播：服务端将聚合后的模型参数广播给所有的客户端
4. 模型更新：所有的客户端根据聚合的模型参数将自身的模型进行更新，并测试更新后的模型性能。

采用降维方法后，每一轮通信中，客户端与服务端的通信量将减少到降维后的参数向量大小。
在具体的降维策略上，常规的方法通常为在每一轮训练中都进行一次PCA的计算，得到降维矩阵进而进行模型压缩。本课题组在研究后认为，这一方法在每一轮中都需要进行额外的计算，且每一轮单独进行降维的效果并不能让人满意。本课题组在参考针对深度神经网络的研究论文后，决定采用基于训练轨迹的降维方法，其过程如下：
1. 采样阶段：系统按照正常联邦学习训练过程进行若干轮训练，且服务器将每一轮聚合后得到的模型保存下来（即保存训练轨迹）。
2. 计算降维矩阵：服务器将前若干轮的模型组接成一个大矩阵，利用PCA方法计算得到降维矩阵，并将此矩阵分发给各个客户端。
3. 本地训练及上传：每个客户端在后续的训练中根据分发的降维矩阵，按照前述方法对本地模型进行降维并上传。
4. 云端聚合：服务端获得各个客户端上传的压缩后的模型，也利用2中得到的PCA矩阵从压缩后的模型中重建原本的模型。
5. 重复进行3和4，直至模型收敛

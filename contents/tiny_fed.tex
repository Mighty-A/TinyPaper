\chapter{基于轨迹降维在联邦学习中的应用}

\section{}


\section{实验}
\subsection{实验设定}
\subsection{实验结果}
\subsection{实验分析}

1. 利用模型训练轨迹进行模型降维压缩
在前期对比各类模型压缩方法后，本课题选择采用PCA降维的方法来降低模型通信开销。采用降维方法后的联邦学习一轮训练过程为：
1. 本地训练：所有客户端根据自身存储的数据计算梯度或参数，并根据特定的降维PCA（主成分）矩阵压缩本地模型，将压缩后的模型上传至服务端。
2. 模型聚合：服务端聚合各个客户端上传的压缩后模型，并根据特定的降维PCA矩阵的逆矩阵重建压缩后的模型。
3. 参数广播：服务端将聚合后的模型参数广播给所有的客户端
4. 模型更新：所有的客户端根据聚合的模型参数将自身的模型进行更新，并测试更新后的模型性能。

采用降维方法后，每一轮通信中，客户端与服务端的通信量将减少到降维后的参数向量大小。
在具体的降维策略上，常规的方法通常为在每一轮训练中都进行一次PCA的计算，得到降维矩阵进而进行模型压缩。本课题组在研究后认为，这一方法在每一轮中都需要进行额外的计算，且每一轮单独进行降维的效果并不能让人满意。本课题组在参考针对深度神经网络的研究论文后，决定采用基于训练轨迹的降维方法，其过程如下：
1. 采样阶段：系统按照正常联邦学习训练过程进行若干轮训练，且服务器将每一轮聚合后得到的模型保存下来（即保存训练轨迹）。
2. 计算降维矩阵：服务器将前若干轮的模型组接成一个大矩阵，利用PCA方法计算得到降维矩阵，并将此矩阵分发给各个客户端。
3. 本地训练及上传：每个客户端在后续的训练中根据分发的降维矩阵，按照前述方法对本地模型进行降维并上传。
4. 云端聚合：服务端获得各个客户端上传的压缩后的模型，也利用2中得到的PCA矩阵从压缩后的模型中重建原本的模型。
5. 重复进行3和4，直至模型收敛
